x-volume: &volume-common
  volumes:
      - /home/hyderreza/codehub/ade-pipeline/keys/gcs-credentials.json:/keys/gcs-credentials.json:ro
      - ./shared-workspace:/opt/workspace
      - ./jobs:/opt/workspace/jobs

x-worker: &worker-common
  image: spark-worker
  environment:
    - SPARK_WORKER_CORES=2
    - SPARK_WORKER_MEMORY=4g
    - GOOGLE_APPLICATION_CREDENTIALS=/keys/gcs-credentials.json
  <<: *volume-common
  depends_on:
    - spark-master
  entrypoint: ["/opt/workspace/runtime-pip-install.sh"]
  command: ["bash", "-c", "spark-class org.apache.spark.deploy.worker.Worker spark://$${SPARK_MASTER_HOST}:$${SPARK_MASTER_PORT} >> $${SPARK_HOME}/logs/spark-worker.out"]


services:
  jupyterlab:
    image: jupyterlab
    container_name: jupyterlab
    ports:
      - 8888:8888
    <<: *volume-common
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/keys/gcs-credentials.json
    entrypoint: ["/opt/workspace/runtime-pip-install.sh"]
    command: ["jupyter", "lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root", "--NotebookApp.token=", "--NotebookApp.disable_check_xsrf=True"]
  spark-master:
    image: spark-master
    container_name: spark-master
    environment:
      - SPARK_LOCAL_IP=spark-master
      - GOOGLE_APPLICATION_CREDENTIALS=/keys/gcs-credentials.json
    entrypoint: ["/opt/workspace/runtime-pip-install.sh"]
    command: ["bash", "-c", "spark-class org.apache.spark.deploy.master.Master >> $${SPARK_HOME}/logs/spark-master.out"]
    ports:
      - 8080:8080 # Spark master UI
      - 4040:4040 # Spark Job UI
      - 7077:7077 # Spark Master (for submitting jobs)
    <<: *volume-common

  worker-1:
    <<: *worker-common
    container_name: spark-worker-1
    ports:
      - 8081:8081
  worker-2:
    <<: *worker-common
    container_name: spark-worker-2
    ports:
      - 8082:8081
  worker-3:
    <<: *worker-common
    container_name: spark-worker-3
    ports:
      - 8083:8081
  worker-4:
    <<: *worker-common
    container_name: spark-worker-4
    ports:
      - 8084:8081